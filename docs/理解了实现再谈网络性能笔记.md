# 理解了实现再谈网络性能笔记

## 内核如何接收网络包

在开始收包之前，LInux的准备工作：

* 创建`ksoftirqd`线程，设置线程函数（处理软中断）
* 协议栈注册（arp、icmp、ip、udp、tcp），注册各自协议的处理函数，便于在数据包来临之后快速找到对应的处理函数
* 网卡驱动初始化，每个驱动都有一个初始化函数，在此过程中，每个驱动自己的DMA准备好，NAPI的poll函数地址告诉内核
* 启动网卡，分配RX、TX队列，注册中断对应的处理函数

数据来临，网卡处理：

* 网卡将数据帧DMA到内存的RingBuffer中，然后向CPU发起中断通知
* CPU响应中断请求，调用网卡启动时注册的中断处理函数（硬中断）
* 硬中断操作简单，记录了一个寄存器，修改了一下CPU的poll_list，发出软中断
* 内核线程ksoftirqd线程发现软中断请求，先关闭所有硬中断
* ksoftirqd线程调用驱动poll函数收包
* poll函数将收到的包送到协议栈注册`ip_rcv`函数
* `ip_rcv`函数将包送到`udp_rcv`函数或者`tcp_rcv`函数





## 内核与进程协作

### udp协议处理

* `udp_tcv`函数中调用`__upd4_lib_rcv`函数，其中的`__udp4_lib_lookup_skb`函数根据skb寻找对应的socket，找到之后将数据包放到socket缓存队列；如果没有找到，发送一个目标不可到达的`icmp`包
* 判断是否在此socket上有系统调用，有则将数据包添加到`backlog`队列；没有则将将数据包直接放在socket接收队列中；当用户释放socket时，内核会检查`backlog`队列，如果有数据就移动到接收队列中（接收队列如果满了，直接将包丢弃）
* `recvfrom`系统调用实现：
  * `recvfrom`是一个`glibc`库函数，执行之后会从用户陷入内核态，进入`sys_recvfrom`
  * socket数据结构中的`const struct proto_ops`对应的是协议的方法集合，对于`IPv4 Internet`来说，`udp`是通过`inet_dgranm_ops`定义的，其中注册了`inet_recvmsg`方法；
  * socket数据结构中的另一个数据结构`struct sock* sk`，其中的`sk_prot`定义了二级处理函数，对于`udp`，设置成`udp_prot`方法集
  * `inet_recvmsg`调用`sk->sk_prot->recvmsg`，进入到`udp_recvmsg`函数，再进入到`__skb_recv_datagram`函数，其中访问了`sk->sk_receive_queue`，如果没有数据且用户允许等待，则调用`wait_for_more_packets()`等待（让用户进入睡眠（睡眠状态与`tcp`的处理一致））





### `tcp`协议处理

**同步阻塞网络IO是高性能网络开发路上的绊脚石！**

* 创建一系列的socket（其中之一）：`sock_create()`->`__sock_create()`

  * `sock_alloc()`分配sock对象->获取协议族操作函数表，调用其`create()`（对于`AF_INET`来说，执行`inet_create()`）
  * 在`inet_create()`根据`SOCK_STREAM`找到对应的`tcp`对应的`inet_stream_ops`和`tcp_prot`，分别设置到`socket->ops`和`sock->sk_prot`，调用`sock_init_data()`
  * `sock_init_data()`将sock中的`sk_data_ready`函数指针进行初始化，默认设置为`sock_def_readable()`（**当软中断上收到数据包时会通过调用`sk_data_ready`函数指针（实际上是`sock_def_readable()`）唤醒sock上的等待的进程**）

* 等待接收数据：

  * `recv`（`clib`库函数）->`recvfrom`系统调用（用户态->内核态）

  * 调用socket对象`ops`里的`recvmsg`（由上述：`inet_recvmsg`），其中调用`sk_prot`里的`recvmsg`（由上述：`tcp_recvmsg`）

  * 遍历接收队列接受的数据：没有收到足够的数据，启用`sk_wait_data`阻塞当前进程；该函数访问的是sock对象下的接收队列`sk->sk_receive_queue`

  * `sk_wait_data()`：

    * 当前进程关联到定义的等待队列（宏`DEFINE_WAIT(wait)`）
    * 调用`sk_sleep`获取sock对象下的wait并准备挂起，将进程状态设置成`INTERRUPTIBLE`（获取sock对象下的等待队列列表头`wait_queue_head_t`）；调用`prepare_to_wait`把新定义的等待队列项wait插入到sock的等待队列下
    * 通过调用`sk_wait_event()`(`schedule_timeout`)让出CPU，然后进入睡眠

    `DEFINE_WAIT(wait)`：定义了一个等待队列项wait，注册回调函数`autoremove_wake_function`，把当前进程描述符`current`关联到`.private`成员上；(**导致一次进程上下文切换开销**)

* 软中断处理模块

  * `tcp_v4_rcv`根据接收到的网络包的`header`里的信息查询对应的socket，之后进入`tcp_v4_do_rcv`
  * 假设处理的是`ESTABLISH`状态下的包，进入`tcp_rcv_established()`
  * 调用`tcp_queue_rcv()`，将接收数据放到socket的接收队列上
  * 调用`sk_data_ready()`唤醒socket上的等待用户进程（函数指针：实际上是调用`sock_def_readable()`）
  * `sock_def_readable()`：访问`sock->sk_wq`的wait，调用`wake_up_interruptible_sync_poll`唤醒socket上因为等待数据被阻塞掉的进程
  * `__wake_up_common`实现唤醒：其中的`nr_exclusive`为1（**这里指的是即使有多个线程阻塞在同一个socket上，也就只唤醒一个进程，作用是防止惊群**）；找出一个等待队列项`curr`，调用`curr->func`（即上述的`autoremove_wake_function()`），调用`default_wake_function()`，调用`try_to_wake_up()`，传入`task_struct`为`curr->private`，就是**当时因为等待而被阻塞的进程项，此时socket上等待而被阻塞的进程被推入可运行队列中，导致又一次进程上下文开销**

